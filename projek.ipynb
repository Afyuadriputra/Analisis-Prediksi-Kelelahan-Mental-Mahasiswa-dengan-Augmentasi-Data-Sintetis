import pandas as pd
import numpy as np
import random

# ==========================================
# GENERATOR DATA DUMMY CERDAS (500 DATA)
# ==========================================

# 1. Definisi Pilihan Jawaban (Sesuai Kuesioner Asli)
options = {
    "Jenis Kelamin": ["Laki-laki", "Perempuan"],
    "Semester:": ["1-2", "3-4", "5-6", "7-8", ">8"],
    "Durasi_Tidur": ["kurang dari 5 jam/ hari", "5-6 jam/ hari", "6-7 jam/ hari", "7-8 jam/ hari", ">8"],
    "Waktu_Tidur": ["Pukul 21.00-22.00", "Pukul 22.00-23.00", "Pukul 23.00-00.00", "Setelah pukul 00.00"],
    "Kualitas_Tidur": ["Sangat Buruk", "Buruk", "Cukup", "Baik", "Sangat Baik"],
    "Frekuensi_Bangun": ["Selalu", "Sering", "Kadang-kadang", "Jarang", "Tidak pernah"],
    "Screen_Time": ["< 1 jam", "1-3 jam", "3-5 jam", "5-8 jam", "> 8 jam"],
    "Aktivitas": ["Media sosial", "Permainan (game)", "Belajar/Tugas", "Menonton film/video", "Kombinasi beberapa aktivitas"],
    "Gadget_Sebelum_Tidur": ["< 30 menit", "30-60 menit", "1-2 jam", "> 2 jam"],
    "Tetap_Main_Walau_Lelah": ["Sangat tidak setuju", "Tidak setuju", "Netral", "Setuju", "Sangat setuju"]
}

# 2. Fungsi untuk Menghasilkan 1 Baris Data dengan Logika
def generate_synthetic_row():
    row = {}

    # --- Generate Fitur Kebiasaan (Features) ---
    row["Jenis Kelamin"] = random.choice(options["Jenis Kelamin"])
    row["Semester:"] = random.choice(options["Semester:"])

    # Kita buat bobot agar data terlihat realistis (misal mahasiswa jarang tidur >8 jam)
    row["Rata-rata urasi tidur malam Anda selama satu minggu terakhir adalah"] = np.random.choice(
        options["Durasi_Tidur"], p=[0.2, 0.3, 0.3, 0.15, 0.05])

    row["Waktu tidur malam paling sering Anda lakukan adalah"] = random.choice(options["Waktu_Tidur"])
    row["Bagaimana kualitas tidur yang dirasakan"] = np.random.choice(
        options["Kualitas_Tidur"], p=[0.1, 0.2, 0.4, 0.2, 0.1])

    row["Seberapa sering Anda terbangun saat tidur malam"] = random.choice(options["Frekuensi_Bangun"])

    row["Rata-rata durasi penggunaan perangkat digital (HP, laptop, tablet) dalam sehari"] = np.random.choice(
        options["Screen_Time"], p=[0.05, 0.1, 0.2, 0.35, 0.3])

    row["Jenis Aktivitas digital paling sering Anda lakukan"] = random.choice(options["Aktivitas"])
    row["Rata-rata durasi penggunaan gadget sebelum tidur"] = random.choice(options["Gadget_Sebelum_Tidur"])
    row["Saya tetap menggunakan perangkat digital meskipun sudah merasa lelah"] = random.choice(options["Tetap_Main_Walau_Lelah"])

    # --- HITUNG "STRESS FACTOR" (LOGIKA SINTETIS) ---
    # Ini rahasianya: Kita hitung skor stress bayangan berdasarkan jawaban di atas
    # Agar Target (Skor Mental) berkorelasi dengan Fitur

    stress_score = 0

    # 1. Faktor Tidur
    tidur = row["Rata-rata urasi tidur malam Anda selama satu minggu terakhir adalah"]
    if "kurang dari 5" in tidur: stress_score += 3
    elif "5-6" in tidur: stress_score += 2

    kualitas = row["Bagaimana kualitas tidur yang dirasakan"]
    if kualitas in ["Sangat Buruk", "Buruk"]: stress_score += 3
    elif kualitas == "Cukup": stress_score += 1

    # 2. Faktor Gadget
    screen = row["Rata-rata durasi penggunaan perangkat digital (HP, laptop, tablet) dalam sehari"]
    if "> 8 jam" in screen or "5-8 jam" in screen: stress_score += 2

    # --- Generate Jawaban Item Mental (Target) Berdasarkan Stress Factor ---
    # Ada 12 Pertanyaan Mental ("Saya merasa...")
    # Jika Stress Factor tinggi, peluang menjawab angka besar (3 atau 4) lebih tinggi

    mental_questions = [
        "Saya merasa kelelahan secara emosional akibat aktivitas perkuliahan",
        "Saya merasa lelah ketika harus memulai kegiatan akademik",
        "Aktivitas studi membuat saya merasa terkuras secara mental",
        "Saya merasa kemampuan saya dalam mengerjakan tugas akademik menurun",
        "Saya merasa usaha belajar saya tidak sebanding dengan hasil yang diperoleh",
        "Saya merasa kurang efektif dalam menyelesaikan tugas akademik",
        "Saya merasa sulit untuk merasa rileks",
        "Saya merasa mudah tegang atau gelisah",
        "Saya merasa sulit untuk beristirahat dengan tenang",
        "Saya merasa kurang bersemangat dalam menjalani aktivitas",
        "Saya merasa kehilangan minat terhadap kegiatan akademik",
        "Saya merasa sulit untuk memulai suatu aktivitas"
    ]

    for q in mental_questions:
        # Base probability (Normal)
        probs = [0.1, 0.2, 0.4, 0.2, 0.1] # Skala 0-4

        # Geser probabilitas jika stress tinggi
        if stress_score >= 5: # Sangat Stress
            probs = [0.05, 0.05, 0.2, 0.4, 0.3] # Cenderung jawab 3 atau 4
        elif stress_score <= 2: # Santai
            probs = [0.4, 0.3, 0.2, 0.05, 0.05] # Cenderung jawab 0 atau 1

        # Pilih jawaban acak berdasarkan probabilitas (0-4)
        row[q] = np.random.choice([0, 1, 2, 3, 4], p=probs)

    return row

# 3. Buat 500 Data Baru
new_rows = [generate_synthetic_row() for _ in range(500)]
df_dummy = pd.DataFrame(new_rows)

print(f"Berhasil membuat {len(df_dummy)} data dummy!")
df_dummy.head()

# ==========================================
# 4. GABUNGKAN DENGAN DATA ASLI
# ==========================================

# Load Data Asli dulu (pastikan path benar)
path_asli = "/content/INSTRUMEN PENELITIAN KELELAHAN MENTAL MAHASISWA (Jawaban) - Form Responses 1.csv"
df_real = pd.read_csv(path_asli)

# Samakan nama kolom (Rapikan spasi seperti kode sebelumnya)
df_real.columns = df_real.columns.astype(str).str.replace(r"\s+", " ", regex=True).str.strip()

# Identifikasi kolom mental di data asli (karena isinya mungkin masih string "Sangat Setuju")
# Kita perlu pastikan data asli dikonversi ke angka dulu sebelum digabung,
# ATAU kita biarkan data dummy berupa angka dan nanti diproses bareng.
# Opsi Aman: Ambil kolom yang sama saja

common_cols = [c for c in df_dummy.columns if c in df_real.columns]

# Gabungkan
df_final = pd.concat([df_real[common_cols], df_dummy[common_cols]], ignore_index=True)

print(f"Total Data Sekarang: {df_final.shape[0]} Baris")

# SEKARANG DATA df_final SIAP DIGUNAKAN DI KODE TRAINING SEBELUMNYA
# Ganti variabel 'df' di kode training menjadi 'df_final'
df = df_final


import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, auc

# ==========================================
# 5. PREPROCESSING DATA GABUNGAN (df)
# ==========================================
# df sekarang berisi Data Asli + Data Dummy

# A. Hitung Skor Mental (Target)
mental_item_cols = [c for c in df.columns if c.startswith("Saya merasa")]
# Pastikan semua jadi angka (karena data asli mungkin string, data dummy integer)
df[mental_item_cols] = df[mental_item_cols].apply(pd.to_numeric, errors="coerce").fillna(0)
df["Skor_Kelelahan_Mental"] = df[mental_item_cols].sum(axis=1)

# B. Buat Target Label (2 Kelas: Rendah vs Tinggi)
# Kita pakai Median dari data gabungan sebagai batas
median_score = df["Skor_Kelelahan_Mental"].median()
df["Target_Label"] = np.where(df["Skor_Kelelahan_Mental"] > median_score, 1, 0) # 1 = Tinggi

print("\n" + "="*40)
print(f"Data Siap! Total Baris: {len(df)}")
print(f"Threshold Skor (Median): {median_score}")
print(f"Proporsi Kelas: {df['Target_Label'].value_counts().to_dict()} (0=Rendah, 1=Tinggi)")
print("="*40)

# C. Mapping Fitur (Agar Model Paham Urutan)
ordinal_mappings = {
    "Bagaimana kualitas tidur yang dirasakan":
        {"Sangat Buruk": 0, "Buruk": 1, "Cukup": 2, "Baik": 3, "Sangat Baik": 4},
    "Seberapa sering Anda terbangun saat tidur malam":
        {"Tidak pernah": 0, "Jarang": 1, "Kadang-kadang": 2, "Sering": 3, "Selalu": 4},
    "Rata-rata urasi tidur malam Anda selama satu minggu terakhir adalah":
        {"kurang dari 5 jam/ hari": 1, "5-6 jam/ hari": 2, "6-7 jam/ hari": 3, "7-8 jam/ hari": 4, ">8": 5}
}

feature_cols = [
    "Jenis Kelamin",
    "Semester:",
    "Rata-rata urasi tidur malam Anda selama satu minggu terakhir adalah",
    "Waktu tidur malam paling sering Anda lakukan adalah",
    "Bagaimana kualitas tidur yang dirasakan",
    "Seberapa sering Anda terbangun saat tidur malam",
    "Rata-rata durasi penggunaan perangkat digital (HP, laptop, tablet) dalam sehari",
    "Jenis Aktivitas digital paling sering Anda lakukan",
    "Rata-rata durasi penggunaan gadget sebelum tidur",
    "Saya tetap menggunakan perangkat digital meskipun sudah merasa lelah",
]

df_model = df.copy()

# Terapkan Mapping Manual
for col, mapping in ordinal_mappings.items():
    if col in df_model.columns:
        df_model[col] = df_model[col].map(mapping).fillna(df_model[col])

X = df_model[feature_cols].copy()
y = df_model["Target_Label"]

# Encode Sisa Kolom Teks (Seperti 'Jenis Kelamin', 'Aktivitas')
for col in X.columns:
    if X[col].dtype == 'object':
        le = LabelEncoder()
        # Pastikan convert ke string dulu untuk handle campuran tipe data
        X[col] = le.fit_transform(X[col].astype(str))
    # Pastikan semua numerik
    X[col] = pd.to_numeric(X[col], errors='coerce').fillna(0)

# ==========================================
# 6. TRAINING & TUNING (DENGAN DATA BANYAK)
# ==========================================

# Split Data (80% Latih, 20% Uji)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Definisi Hyperparameter Grid
# Karena data sudah banyak (500+), kita bisa pakai pohon yang lebih dalam (max_depth lebih besar)
param_grid = {
    'n_estimators': [200, 300],
    'max_depth': [5, 10, None],        # Coba None karena data dummy punya pola kuat
    'min_samples_split': [2, 5],
    'max_features': ['sqrt'],
    'class_weight': ['balanced']
}

print("\nSedang Melatih Model dengan Data Gabungan...")
rf_grid = GridSearchCV(
    estimator=RandomForestClassifier(random_state=42),
    param_grid=param_grid,
    cv=StratifiedKFold(n_splits=5),
    scoring='accuracy',
    n_jobs=-1
)

rf_grid.fit(X_train, y_train)
best_rf = rf_grid.best_estimator_

print(f"Parameter Terbaik: {rf_grid.best_params_}")

# ==========================================
# 7. PROBABILITY THRESHOLD TUNING
# ==========================================
# Mencari batas probability terbaik
y_proba = best_rf.predict_proba(X_test)[:, 1]

best_threshold = 0.5
best_acc = 0
thresholds = np.arange(0.3, 0.7, 0.01)

for thresh in thresholds:
    y_pred_temp = (y_proba >= thresh).astype(int)
    acc = accuracy_score(y_test, y_pred_temp)
    if acc > best_acc:
        best_acc = acc
        best_threshold = thresh

y_final_pred = (y_proba >= best_threshold).astype(int)

print("\n" + "="*40)
print(f"AKURASI AKHIR (AUGMENTED DATA): {best_acc:.2%}")
print(f"Threshold Terbaik: {best_threshold:.2f}")
print("="*40)

# ==========================================
# 8. VISUALISASI HASIL
# ==========================================

# Confusion Matrix
plt.figure(figsize=(6,5))
cm = confusion_matrix(y_test, y_final_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Rendah', 'Tinggi'], yticklabels=['Rendah', 'Tinggi'])
plt.title(f"Confusion Matrix (Data Gabungan)")
plt.xlabel("Prediksi")
plt.ylabel("Aktual")
plt.show()

# Classification Report
print("\nClassification Report:\n", classification_report(y_test, y_final_pred))

# Feature Importance
feat_imp = pd.Series(best_rf.feature_importances_, index=X.columns).sort_values(ascending=False)
plt.figure(figsize=(8,5))
feat_imp.nlargest(10).plot(kind='barh', color='teal').invert_yaxis()
plt.title("Faktor Paling Berpengaruh (Model Data Gabungan)")
plt.show()

# ROC Curve
fpr, tpr, _ = roc_curve(y_test, y_proba)
roc_auc = auc(fpr, tpr)
plt.figure(figsize=(6,5))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
plt.legend(loc="lower right")
plt.title('ROC Curve')
plt.show()

output:
